{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0de9f49",
   "metadata": {},
   "source": [
    "# Detecting hot posts by classification\n",
    "\n",
    "1. 目的：我們收到社群輿論資料共一萬多筆貼文（posts），想要從裡面建立一個分類模型來偵測什麼樣的貼文會「爆」（假設某則post有超過100則回文（comments），以PTT的語彙來說，就是爆了）。\n",
    "2. 依變項（Dependent）：依變項為每則posts的回文數，把100則回文以上的文章視為1，把少於100則回文的視為0（切勿不可將回文數當成自變項，如果這麼做就會被扣很多分數）。但你也可以嘗試以不一樣的方式去切割，但要注意盡可能保持1/0兩個分類貼文數的平衡。\n",
    "3. 自變項（Independent）：至少要以貼文內容作為自變項，但可以用貼文標題、貼文作者、貼文時間來訓練。除此之外，我們還提供了前10則回文，說不定影響一則貼文會不會爆的主要因素是前十則回文。你可以自己決定要不要把回文丟下去當自變項。本作業的要求只有要求要用貼文當自變項。\n",
    "4. 參考版本：助教用simpletransformer寫了個[版本](https://colab.research.google.com/drive/1YQZNlzH_mo7_Q3XU8X2sIpkhrQZWVYar?usp=sharing)給各位參考，但作為示範助教僅使用了貼文內容作為特徵來訓練模型、也使用了較少的資料集（在時間上做了點切割）。你可以使用全部的貼文來預測，或者可以嘗試加入每則貼文的前10則回文來預測。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0df87",
   "metadata": {},
   "source": [
    "# 讀取資料\n",
    "1. 貼文資料https://github.com/p4css/PSS/blob/master/data/ptt_post.pickle\n",
    "2. 回文資料https://github.com/p4css/PSS/blob/master/data/ptt_comment10.pickle \n",
    "貼文與相對應的回文資料均以plink作為key，可以用pandas的merge將兩個資料集給連結起來做訓練。但要怎麼把前十則的回文化為貼文特徵，要想想。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d573b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.618 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plink</th>\n",
       "      <th>board</th>\n",
       "      <th>pcontent</th>\n",
       "      <th>poster</th>\n",
       "      <th>ptitle</th>\n",
       "      <th>ptime</th>\n",
       "      <th>ipaddr</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>Ncomment</th>\n",
       "      <th>explode</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119222660....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n 看到這推文,忍不住要寫一個飛機沒油的例子\\n 很久之前在讀者文摘上看到,現憑印象寫...</td>\n",
       "      <td>Muroi (I Honestly Love You)</td>\n",
       "      <td>Re: (問題)華航空難留言</td>\n",
       "      <td>Mon Jun 20 07:28:27 2005</td>\n",
       "      <td>138.130.212.179</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>1</td>\n",
       "      <td>看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...</td>\n",
       "      <td>[看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119233779....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n那不是為了反盜版\\n那是為了捐錢給消基會\\n當年美國唱了 WE ARE THE WORL...</td>\n",
       "      <td>JCC (JCC                    )</td>\n",
       "      <td>Re: 有沒有明天會更好的八卦</td>\n",
       "      <td>Mon Jun 20 10:21:53 2005</td>\n",
       "      <td>211.20.78.69</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119257927....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n我聽到的是：\\n記者問張跟路有沒有要結婚\\n　　　家人有沒有在催。。。巴拉巴拉的\\n...</td>\n",
       "      <td>vancie (我不正 我很歪 )</td>\n",
       "      <td>Re: [新聞] 張震月的八卦有嗎？</td>\n",
       "      <td>Mon Jun 20 17:07:13 2005</td>\n",
       "      <td>※ 發信站: 批踢踢實業坊(ptt.cc)</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>我聽到的是： 記者問張跟路有沒有要結婚 　　　家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就...</td>\n",
       "      <td>[我, 聽, 到, 的, 是, ：,  , 記者, 問張, 跟, 路, 有, 沒, 有, 要...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119258686....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n太想被M,得到P幣\\n再八卦一下\\n\\n桌伯元先生真的不是台大法學碩士\\n\\n它是\\n國...</td>\n",
       "      <td>J1 (andy)</td>\n",
       "      <td>Re: [政商] 請問桌伯元的八卦?</td>\n",
       "      <td>Mon Jun 20 17:18:14 2005</td>\n",
       "      <td>220.141.159.23</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...</td>\n",
       "      <td>[太想, 被, M, ,, 得到, P, 幣,  , 再, 八卦, 一下,  , 桌伯元, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119271499....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n米其林是家輪胎公司\\n米其林兄弟發行了一本只送不賣的輪胎手冊\\n讓所有自動車 自行車...</td>\n",
       "      <td>ilcd (南特 巴黎 白朗峰!!! )</td>\n",
       "      <td>Re: 有沒有米其淋的美食還是什麼評鑑八卦</td>\n",
       "      <td>Mon Jun 20 20:53:24 2005</td>\n",
       "      <td>218.167.152.79</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...</td>\n",
       "      <td>[米其林, 是, 家, 輪胎, 公司,  , 米其林, 兄弟, 發行, 了, 一本, 只, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               plink      board  \\\n",
       "0  https://www.ptt.cc/bbs/Gossiping/M.1119222660....  Gossiping   \n",
       "1  https://www.ptt.cc/bbs/Gossiping/M.1119233779....  Gossiping   \n",
       "2  https://www.ptt.cc/bbs/Gossiping/M.1119257927....  Gossiping   \n",
       "3  https://www.ptt.cc/bbs/Gossiping/M.1119258686....  Gossiping   \n",
       "4  https://www.ptt.cc/bbs/Gossiping/M.1119271499....  Gossiping   \n",
       "\n",
       "                                            pcontent  \\\n",
       "0  \\n\\n 看到這推文,忍不住要寫一個飛機沒油的例子\\n 很久之前在讀者文摘上看到,現憑印象寫...   \n",
       "1  \\n那不是為了反盜版\\n那是為了捐錢給消基會\\n當年美國唱了 WE ARE THE WORL...   \n",
       "2  \\n\\n我聽到的是：\\n記者問張跟路有沒有要結婚\\n　　　家人有沒有在催。。。巴拉巴拉的\\n...   \n",
       "3  \\n太想被M,得到P幣\\n再八卦一下\\n\\n桌伯元先生真的不是台大法學碩士\\n\\n它是\\n國...   \n",
       "4  \\n\\n米其林是家輪胎公司\\n米其林兄弟發行了一本只送不賣的輪胎手冊\\n讓所有自動車 自行車...   \n",
       "\n",
       "                          poster                 ptitle  \\\n",
       "0    Muroi (I Honestly Love You)         Re: (問題)華航空難留言   \n",
       "1  JCC (JCC                    )        Re: 有沒有明天會更好的八卦   \n",
       "2              vancie (我不正 我很歪 )     Re: [新聞] 張震月的八卦有嗎？   \n",
       "3                      J1 (andy)     Re: [政商] 請問桌伯元的八卦?   \n",
       "4           ilcd (南特 巴黎 白朗峰!!! )  Re: 有沒有米其淋的美食還是什麼評鑑八卦   \n",
       "\n",
       "                      ptime                 ipaddr  ip.len  Ncomment  explode  \\\n",
       "0  Mon Jun 20 07:28:27 2005        138.130.212.179       1       944        1   \n",
       "1  Mon Jun 20 10:21:53 2005           211.20.78.69       1       350        1   \n",
       "2  Mon Jun 20 17:07:13 2005  ※ 發信站: 批踢踢實業坊(ptt.cc)       0       156        1   \n",
       "3  Mon Jun 20 17:18:14 2005         220.141.159.23       1       160        1   \n",
       "4  Mon Jun 20 20:53:24 2005         218.167.152.79       1       153        1   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...   \n",
       "1  那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...   \n",
       "2  我聽到的是： 記者問張跟路有沒有要結婚 　　　家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就...   \n",
       "3  太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...   \n",
       "4  米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...   \n",
       "\n",
       "                                          token_text  \n",
       "0  [看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...  \n",
       "1  [那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...  \n",
       "2  [我, 聽, 到, 的, 是, ：,  , 記者, 問張, 跟, 路, 有, 沒, 有, 要...  \n",
       "3  [太想, 被, M, ,, 得到, P, 幣,  , 再, 八卦, 一下,  , 桌伯元, ...  \n",
       "4  [米其林, 是, 家, 輪胎, 公司,  , 米其林, 兄弟, 發行, 了, 一本, 只, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import jieba\n",
    "df = pd.read_pickle('data/ptt_post.pickle')\n",
    "\n",
    "#將\"爆\"的貼文設定為1，訂在df['explode']\n",
    "explosion = []\n",
    "for comm in df['Ncomment']:\n",
    "    if comm >= 100:\n",
    "        explosion.append(1)\n",
    "    else:\n",
    "        explosion.append(0)\n",
    "\n",
    "df['explode'] = explosion\n",
    "\n",
    "#清理貼文內容\n",
    "df['cleaned'] = df.pcontent.apply(lambda x: re.sub(r'\\n+', '\\n', x).strip())\n",
    "df['cleaned'] = df.cleaned.apply(lambda x: x.replace('\\n', ' ').strip()[:])\n",
    "df['token_text'] = df['cleaned'].apply(lambda x:list(jieba.cut(x)))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5f7c88-ae2b-41da-9831-e3b4ec416e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plink</th>\n",
       "      <th>board</th>\n",
       "      <th>pcontent</th>\n",
       "      <th>poster</th>\n",
       "      <th>ptitle</th>\n",
       "      <th>ptime</th>\n",
       "      <th>ipaddr</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>Ncomment</th>\n",
       "      <th>explode</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>token_text</th>\n",
       "      <th>final_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119222660....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n 看到這推文,忍不住要寫一個飛機沒油的例子\\n 很久之前在讀者文摘上看到,現憑印象寫...</td>\n",
       "      <td>Muroi (I Honestly Love You)</td>\n",
       "      <td>Re: (問題)華航空難留言</td>\n",
       "      <td>Mon Jun 20 07:28:27 2005</td>\n",
       "      <td>138.130.212.179</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>1</td>\n",
       "      <td>看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...</td>\n",
       "      <td>[看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...</td>\n",
       "      <td>[看到, 這推文, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子, 很, 久, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119233779....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n那不是為了反盜版\\n那是為了捐錢給消基會\\n當年美國唱了 WE ARE THE WORL...</td>\n",
       "      <td>JCC (JCC                    )</td>\n",
       "      <td>Re: 有沒有明天會更好的八卦</td>\n",
       "      <td>Mon Jun 20 10:21:53 2005</td>\n",
       "      <td>211.20.78.69</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版, 那, 是, 為, 了, 捐, 錢給, 消基會, 當...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119257927....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n我聽到的是：\\n記者問張跟路有沒有要結婚\\n　　　家人有沒有在催。。。巴拉巴拉的\\n...</td>\n",
       "      <td>vancie (我不正 我很歪 )</td>\n",
       "      <td>Re: [新聞] 張震月的八卦有嗎？</td>\n",
       "      <td>Mon Jun 20 17:07:13 2005</td>\n",
       "      <td>※ 發信站: 批踢踢實業坊(ptt.cc)</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>我聽到的是： 記者問張跟路有沒有要結婚 　　　家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就...</td>\n",
       "      <td>[我, 聽, 到, 的, 是, ：,  , 記者, 問張, 跟, 路, 有, 沒, 有, 要...</td>\n",
       "      <td>[我, 聽, 到, 的, 是, 記者, 問張, 跟, 路, 有, 沒, 有, 要, 結婚, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119258686....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n太想被M,得到P幣\\n再八卦一下\\n\\n桌伯元先生真的不是台大法學碩士\\n\\n它是\\n國...</td>\n",
       "      <td>J1 (andy)</td>\n",
       "      <td>Re: [政商] 請問桌伯元的八卦?</td>\n",
       "      <td>Mon Jun 20 17:18:14 2005</td>\n",
       "      <td>220.141.159.23</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...</td>\n",
       "      <td>[太想, 被, M, ,, 得到, P, 幣,  , 再, 八卦, 一下,  , 桌伯元, ...</td>\n",
       "      <td>[太想, 被, M, 得到, P, 幣, 再, 八卦, 一下, 桌伯元, 先生, 真的, 不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119271499....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n米其林是家輪胎公司\\n米其林兄弟發行了一本只送不賣的輪胎手冊\\n讓所有自動車 自行車...</td>\n",
       "      <td>ilcd (南特 巴黎 白朗峰!!! )</td>\n",
       "      <td>Re: 有沒有米其淋的美食還是什麼評鑑八卦</td>\n",
       "      <td>Mon Jun 20 20:53:24 2005</td>\n",
       "      <td>218.167.152.79</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...</td>\n",
       "      <td>[米其林, 是, 家, 輪胎, 公司,  , 米其林, 兄弟, 發行, 了, 一本, 只, ...</td>\n",
       "      <td>[米其林, 是, 家, 輪胎, 公司, 米其林, 兄弟, 發行, 了, 一本, 只, 送, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               plink      board  \\\n",
       "0  https://www.ptt.cc/bbs/Gossiping/M.1119222660....  Gossiping   \n",
       "1  https://www.ptt.cc/bbs/Gossiping/M.1119233779....  Gossiping   \n",
       "2  https://www.ptt.cc/bbs/Gossiping/M.1119257927....  Gossiping   \n",
       "3  https://www.ptt.cc/bbs/Gossiping/M.1119258686....  Gossiping   \n",
       "4  https://www.ptt.cc/bbs/Gossiping/M.1119271499....  Gossiping   \n",
       "\n",
       "                                            pcontent  \\\n",
       "0  \\n\\n 看到這推文,忍不住要寫一個飛機沒油的例子\\n 很久之前在讀者文摘上看到,現憑印象寫...   \n",
       "1  \\n那不是為了反盜版\\n那是為了捐錢給消基會\\n當年美國唱了 WE ARE THE WORL...   \n",
       "2  \\n\\n我聽到的是：\\n記者問張跟路有沒有要結婚\\n　　　家人有沒有在催。。。巴拉巴拉的\\n...   \n",
       "3  \\n太想被M,得到P幣\\n再八卦一下\\n\\n桌伯元先生真的不是台大法學碩士\\n\\n它是\\n國...   \n",
       "4  \\n\\n米其林是家輪胎公司\\n米其林兄弟發行了一本只送不賣的輪胎手冊\\n讓所有自動車 自行車...   \n",
       "\n",
       "                          poster                 ptitle  \\\n",
       "0    Muroi (I Honestly Love You)         Re: (問題)華航空難留言   \n",
       "1  JCC (JCC                    )        Re: 有沒有明天會更好的八卦   \n",
       "2              vancie (我不正 我很歪 )     Re: [新聞] 張震月的八卦有嗎？   \n",
       "3                      J1 (andy)     Re: [政商] 請問桌伯元的八卦?   \n",
       "4           ilcd (南特 巴黎 白朗峰!!! )  Re: 有沒有米其淋的美食還是什麼評鑑八卦   \n",
       "\n",
       "                      ptime                 ipaddr  ip.len  Ncomment  explode  \\\n",
       "0  Mon Jun 20 07:28:27 2005        138.130.212.179       1       944        1   \n",
       "1  Mon Jun 20 10:21:53 2005           211.20.78.69       1       350        1   \n",
       "2  Mon Jun 20 17:07:13 2005  ※ 發信站: 批踢踢實業坊(ptt.cc)       0       156        1   \n",
       "3  Mon Jun 20 17:18:14 2005         220.141.159.23       1       160        1   \n",
       "4  Mon Jun 20 20:53:24 2005         218.167.152.79       1       153        1   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...   \n",
       "1  那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...   \n",
       "2  我聽到的是： 記者問張跟路有沒有要結婚 　　　家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就...   \n",
       "3  太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...   \n",
       "4  米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...   \n",
       "\n",
       "                                          token_text  \\\n",
       "0  [看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...   \n",
       "1  [那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...   \n",
       "2  [我, 聽, 到, 的, 是, ：,  , 記者, 問張, 跟, 路, 有, 沒, 有, 要...   \n",
       "3  [太想, 被, M, ,, 得到, P, 幣,  , 再, 八卦, 一下,  , 桌伯元, ...   \n",
       "4  [米其林, 是, 家, 輪胎, 公司,  , 米其林, 兄弟, 發行, 了, 一本, 只, ...   \n",
       "\n",
       "                                       final_cleaned  \n",
       "0  [看到, 這推文, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子, 很, 久, ...  \n",
       "1  [那, 不是, 為, 了, 反盜, 版, 那, 是, 為, 了, 捐, 錢給, 消基會, 當...  \n",
       "2  [我, 聽, 到, 的, 是, 記者, 問張, 跟, 路, 有, 沒, 有, 要, 結婚, ...  \n",
       "3  [太想, 被, M, 得到, P, 幣, 再, 八卦, 一下, 桌伯元, 先生, 真的, 不...  \n",
       "4  [米其林, 是, 家, 輪胎, 公司, 米其林, 兄弟, 發行, 了, 一本, 只, 送, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation\n",
    "def remove_punc_by_unicode(words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        if word != \" \" and not unicodedata.category(word[0]).startswith('P'):\n",
    "            out.append(word)\n",
    "    return out\n",
    "\n",
    "df['final_cleaned'] = df['token_text'].apply(remove_punc_by_unicode)\n",
    "# post = post.sample(frac=0.5)\n",
    "df.head()\n",
    "        \n",
    "\n",
    "# print(df['explode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accfa006-7006-4810-abaa-cd9af98bd6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re: 有沒有米其淋的美食還是什麼評鑑八卦\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plink</th>\n",
       "      <th>board</th>\n",
       "      <th>pcontent</th>\n",
       "      <th>poster</th>\n",
       "      <th>ptitle</th>\n",
       "      <th>ptime</th>\n",
       "      <th>ipaddr</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>Ncomment</th>\n",
       "      <th>explode</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>token_text</th>\n",
       "      <th>final_cleaned</th>\n",
       "      <th>token_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119222660....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n 看到這推文,忍不住要寫一個飛機沒油的例子\\n 很久之前在讀者文摘上看到,現憑印象寫...</td>\n",
       "      <td>Muroi (I Honestly Love You)</td>\n",
       "      <td>Re: (問題)華航空難留言</td>\n",
       "      <td>Mon Jun 20 07:28:27 2005</td>\n",
       "      <td>138.130.212.179</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>1</td>\n",
       "      <td>看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...</td>\n",
       "      <td>[看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...</td>\n",
       "      <td>[看到, 這推文, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子, 很, 久, ...</td>\n",
       "      <td>[tRe, t問題, t華, t航空, t難, t留言]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119233779....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n那不是為了反盜版\\n那是為了捐錢給消基會\\n當年美國唱了 WE ARE THE WORL...</td>\n",
       "      <td>JCC (JCC                    )</td>\n",
       "      <td>Re: 有沒有明天會更好的八卦</td>\n",
       "      <td>Mon Jun 20 10:21:53 2005</td>\n",
       "      <td>211.20.78.69</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版, 那, 是, 為, 了, 捐, 錢給, 消基會, 當...</td>\n",
       "      <td>[tRe, t有, t沒, t有, t明天, t會, t更好, t的, t八卦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119257927....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n我聽到的是：\\n記者問張跟路有沒有要結婚\\n　　　家人有沒有在催。。。巴拉巴拉的\\n...</td>\n",
       "      <td>vancie (我不正 我很歪 )</td>\n",
       "      <td>Re: [新聞] 張震月的八卦有嗎？</td>\n",
       "      <td>Mon Jun 20 17:07:13 2005</td>\n",
       "      <td>※ 發信站: 批踢踢實業坊(ptt.cc)</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>我聽到的是： 記者問張跟路有沒有要結婚 　　　家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就...</td>\n",
       "      <td>[我, 聽, 到, 的, 是, ：,  , 記者, 問張, 跟, 路, 有, 沒, 有, 要...</td>\n",
       "      <td>[我, 聽, 到, 的, 是, 記者, 問張, 跟, 路, 有, 沒, 有, 要, 結婚, ...</td>\n",
       "      <td>[tRe, t新聞, t張震, t月, t的, t八卦, t有, t嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119258686....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n太想被M,得到P幣\\n再八卦一下\\n\\n桌伯元先生真的不是台大法學碩士\\n\\n它是\\n國...</td>\n",
       "      <td>J1 (andy)</td>\n",
       "      <td>Re: [政商] 請問桌伯元的八卦?</td>\n",
       "      <td>Mon Jun 20 17:18:14 2005</td>\n",
       "      <td>220.141.159.23</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...</td>\n",
       "      <td>[太想, 被, M, ,, 得到, P, 幣,  , 再, 八卦, 一下,  , 桌伯元, ...</td>\n",
       "      <td>[太想, 被, M, 得到, P, 幣, 再, 八卦, 一下, 桌伯元, 先生, 真的, 不...</td>\n",
       "      <td>[tRe, t政商, t請問, t桌伯元, t的, t八卦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119271499....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>\\n\\n米其林是家輪胎公司\\n米其林兄弟發行了一本只送不賣的輪胎手冊\\n讓所有自動車 自行車...</td>\n",
       "      <td>ilcd (南特 巴黎 白朗峰!!! )</td>\n",
       "      <td>Re: 有沒有米其淋的美食還是什麼評鑑八卦</td>\n",
       "      <td>Mon Jun 20 20:53:24 2005</td>\n",
       "      <td>218.167.152.79</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...</td>\n",
       "      <td>[米其林, 是, 家, 輪胎, 公司,  , 米其林, 兄弟, 發行, 了, 一本, 只, ...</td>\n",
       "      <td>[米其林, 是, 家, 輪胎, 公司, 米其林, 兄弟, 發行, 了, 一本, 只, 送, ...</td>\n",
       "      <td>[tRe, t有, t沒, t有, t米, t其淋, t的, t美食, t還是, t什麼, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               plink      board  \\\n",
       "0  https://www.ptt.cc/bbs/Gossiping/M.1119222660....  Gossiping   \n",
       "1  https://www.ptt.cc/bbs/Gossiping/M.1119233779....  Gossiping   \n",
       "2  https://www.ptt.cc/bbs/Gossiping/M.1119257927....  Gossiping   \n",
       "3  https://www.ptt.cc/bbs/Gossiping/M.1119258686....  Gossiping   \n",
       "4  https://www.ptt.cc/bbs/Gossiping/M.1119271499....  Gossiping   \n",
       "\n",
       "                                            pcontent  \\\n",
       "0  \\n\\n 看到這推文,忍不住要寫一個飛機沒油的例子\\n 很久之前在讀者文摘上看到,現憑印象寫...   \n",
       "1  \\n那不是為了反盜版\\n那是為了捐錢給消基會\\n當年美國唱了 WE ARE THE WORL...   \n",
       "2  \\n\\n我聽到的是：\\n記者問張跟路有沒有要結婚\\n　　　家人有沒有在催。。。巴拉巴拉的\\n...   \n",
       "3  \\n太想被M,得到P幣\\n再八卦一下\\n\\n桌伯元先生真的不是台大法學碩士\\n\\n它是\\n國...   \n",
       "4  \\n\\n米其林是家輪胎公司\\n米其林兄弟發行了一本只送不賣的輪胎手冊\\n讓所有自動車 自行車...   \n",
       "\n",
       "                          poster                 ptitle  \\\n",
       "0    Muroi (I Honestly Love You)         Re: (問題)華航空難留言   \n",
       "1  JCC (JCC                    )        Re: 有沒有明天會更好的八卦   \n",
       "2              vancie (我不正 我很歪 )     Re: [新聞] 張震月的八卦有嗎？   \n",
       "3                      J1 (andy)     Re: [政商] 請問桌伯元的八卦?   \n",
       "4           ilcd (南特 巴黎 白朗峰!!! )  Re: 有沒有米其淋的美食還是什麼評鑑八卦   \n",
       "\n",
       "                      ptime                 ipaddr  ip.len  Ncomment  explode  \\\n",
       "0  Mon Jun 20 07:28:27 2005        138.130.212.179       1       944        1   \n",
       "1  Mon Jun 20 10:21:53 2005           211.20.78.69       1       350        1   \n",
       "2  Mon Jun 20 17:07:13 2005  ※ 發信站: 批踢踢實業坊(ptt.cc)       0       156        1   \n",
       "3  Mon Jun 20 17:18:14 2005         220.141.159.23       1       160        1   \n",
       "4  Mon Jun 20 20:53:24 2005         218.167.152.79       1       153        1   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...   \n",
       "1  那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...   \n",
       "2  我聽到的是： 記者問張跟路有沒有要結婚 　　　家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就...   \n",
       "3  太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...   \n",
       "4  米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...   \n",
       "\n",
       "                                          token_text  \\\n",
       "0  [看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...   \n",
       "1  [那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...   \n",
       "2  [我, 聽, 到, 的, 是, ：,  , 記者, 問張, 跟, 路, 有, 沒, 有, 要...   \n",
       "3  [太想, 被, M, ,, 得到, P, 幣,  , 再, 八卦, 一下,  , 桌伯元, ...   \n",
       "4  [米其林, 是, 家, 輪胎, 公司,  , 米其林, 兄弟, 發行, 了, 一本, 只, ...   \n",
       "\n",
       "                                       final_cleaned  \\\n",
       "0  [看到, 這推文, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子, 很, 久, ...   \n",
       "1  [那, 不是, 為, 了, 反盜, 版, 那, 是, 為, 了, 捐, 錢給, 消基會, 當...   \n",
       "2  [我, 聽, 到, 的, 是, 記者, 問張, 跟, 路, 有, 沒, 有, 要, 結婚, ...   \n",
       "3  [太想, 被, M, 得到, P, 幣, 再, 八卦, 一下, 桌伯元, 先生, 真的, 不...   \n",
       "4  [米其林, 是, 家, 輪胎, 公司, 米其林, 兄弟, 發行, 了, 一本, 只, 送, ...   \n",
       "\n",
       "                                         token_title  \n",
       "0                       [tRe, t問題, t華, t航空, t難, t留言]  \n",
       "1           [tRe, t有, t沒, t有, t明天, t會, t更好, t的, t八卦]  \n",
       "2               [tRe, t新聞, t張震, t月, t的, t八卦, t有, t嗎]  \n",
       "3                     [tRe, t政商, t請問, t桌伯元, t的, t八卦]  \n",
       "4  [tRe, t有, t沒, t有, t米, t其淋, t的, t美食, t還是, t什麼, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.at[4, 'ptitle'][:])\n",
    "df['token_title'] = df['ptitle'].astype(\"str\").apply(lambda x:list(jieba.cut(x)))\n",
    "\n",
    "df['token_title'] = df['token_title'].apply(remove_punc_by_unicode)\n",
    "\n",
    "\n",
    "def plus_t(words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        out.append(\"t\"+word)\n",
    "    return out\n",
    "df['token_title'] = df['token_title'].apply(plus_t)\n",
    "\n",
    "df.head()\n",
    "# df['cleaned_title'] = df.ptitle.apply(lambda x: str.replace(\"Re: \", \" \"))\n",
    "# df.head(2)\n",
    "# def clean_title(words):\n",
    "#     out = []\n",
    "#     for word in words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73748214-8ba8-4384-919b-30b81d830e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tRe t有 t沒 t有 t明天 t會 t更好 t的 t八卦 那 不是 為 了 反盜 版 那 是 為 了 捐 錢給 消基會 當年 美國 唱 了 WE ARE THE WORLD 之 後 台灣 這些 歌手 也 覺得 該 如法 泡 製 一番 但 當年 國家 安定 人民富足 實在 找不出 啥 理由 於 是 就 拿 來 捐給 消基會 了 至於 為後來 很多 人會誤 傳是 為 了 反盜 版 我 也 不 知道 大慨 是 捐給 消基會 這個 理由 蠻妙 的 吧 以上 是 我 記憶 的 東西 網 路上 找到 一篇 文 可以 佐證 當年 大合唱 的 歌曲 還有 滾石 的 快樂 天堂 唱給 動物園 搬家 用 的 還有 飛 碟 的 飛向 未來 好像 只是 幾 周年 慶用 的 至於 後 來 八九天 安門 屠殺 後 的 歷史 的 傷口 讓 童安格 被 大陸禁 了 好 幾年 ◆ From 211.20 78.69\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(12149, 220906)\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/stopwords_zh-tw.txt\", encoding=\"utf-8\") as fin:\n",
    "    stopwords = fin.read().split(\"\\n\")[1:]\n",
    "stopwords.append('\\u3000')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#document1=內文，document2=標題，將兩者混和在一起丟進document中\n",
    "documents1 = [\" \".join(doc) for doc in df['final_cleaned']]\n",
    "documents2 = [\" \".join(doc) for doc in df['token_title']]\n",
    "documents = []\n",
    "for i in range(len(documents1)):\n",
    "    documents.append(documents2[i] +\" \"+ documents1[i])\n",
    "print(documents[1])\n",
    "\n",
    "\n",
    "# X1 = np.asarray(df[['city', 'num_employees', 'store', 'units_sold']])\n",
    "\n",
    "\n",
    "\n",
    "model_tfidf = TfidfVectorizer(max_df=0.05,\n",
    "                              # token_pattern=r\"(?u)\\b\\w+\\b\", \n",
    "                              # max_features = 2000,\n",
    "                              stop_words=stopwords).fit(documents)\n",
    "\n",
    "\n",
    "X_tfidf = model_tfidf.transform(documents)\n",
    "print(type(X_tfidf))\n",
    "print(X_tfidf.shape)\n",
    "# print(X_tfidf)\n",
    "# model_tfidf.inverse_transform(X_tfidf)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d30d5c",
   "metadata": {},
   "source": [
    "# 切割資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468fafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#將explode變相設為y\n",
    "y = df.iloc[:, 9]\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde61c6b",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4795f-2321-4a9d-a1d8-d07c08ce0465",
   "metadata": {},
   "source": [
    "## 篩選tfidf變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891c786e-036c-4cb7-8046-b5a454f3de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36209f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['?', '、',\n",
       "                                                                    '。', '“',\n",
       "                                                                    '”', '《',\n",
       "                                                                    '》', '！',\n",
       "                                                                    '，', '：',\n",
       "                                                                    '；', '？',\n",
       "                                                                    '人民',\n",
       "                                                                    '末##末', '啊',\n",
       "                                                                    '阿', '哎',\n",
       "                                                                    '哎呀', '哎喲',\n",
       "                                                                    '唉', '我',\n",
       "                                                                    '我們', '按',\n",
       "                                                                    '按照', '依照',\n",
       "                                                                    '吧', '吧噠',\n",
       "                                                                    '把', '罷了',\n",
       "                                                                    '被', ...])),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tfidf__max_df': [0.01, 0.05, 0.1, 0.2, 1.0],\n",
       "                         'tfidf__max_features': [10000, 15000, 20000],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipe= Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression())\n",
    "    # ('RF': RandomForestClassifier()),\n",
    "    # ('NB': GaussianNB())\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_df': [0.01, 0.05, 0.1, 0.2, 1.0],\n",
    "#     'tfidf__token_pattern': [r\"(?u)\\b\\w+\\b\", r\"(?u)\\b\\w\\w+\\b\"],\n",
    "    'tfidf__max_features': [10000, 15000, 20000]\n",
    "#     'clf__penalty': ('l1', 'l2', 'none'),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose = 3)\n",
    "grid.fit(documents, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5475fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6801393653843222\n",
      "Params: \n",
      "tfidf__max_df: 1.0\n",
      "tfidf__max_features: 20000\n",
      "tfidf__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(\"Params: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f14c4e6b-78ac-420c-a5f2-bea2cd5367cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__max_df</th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.578601</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.594239</td>\n",
       "      <td>0.617126</td>\n",
       "      <td>0.603425</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.576132</td>\n",
       "      <td>0.616049</td>\n",
       "      <td>0.623457</td>\n",
       "      <td>0.605350</td>\n",
       "      <td>0.606834</td>\n",
       "      <td>0.605564</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.576543</td>\n",
       "      <td>0.614403</td>\n",
       "      <td>0.616049</td>\n",
       "      <td>0.596296</td>\n",
       "      <td>0.615068</td>\n",
       "      <td>0.603672</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.583951</td>\n",
       "      <td>0.616049</td>\n",
       "      <td>0.628807</td>\n",
       "      <td>0.610288</td>\n",
       "      <td>0.620420</td>\n",
       "      <td>0.611903</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.615226</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.602058</td>\n",
       "      <td>0.618361</td>\n",
       "      <td>0.606141</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.589712</td>\n",
       "      <td>0.608642</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.610700</td>\n",
       "      <td>0.624125</td>\n",
       "      <td>0.612562</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.606173</td>\n",
       "      <td>0.630041</td>\n",
       "      <td>0.650206</td>\n",
       "      <td>0.621399</td>\n",
       "      <td>0.643886</td>\n",
       "      <td>0.630341</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.610700</td>\n",
       "      <td>0.635802</td>\n",
       "      <td>0.655144</td>\n",
       "      <td>0.632922</td>\n",
       "      <td>0.648827</td>\n",
       "      <td>0.636679</td>\n",
       "      <td>0.015351</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.608230</td>\n",
       "      <td>0.627160</td>\n",
       "      <td>0.655967</td>\n",
       "      <td>0.627160</td>\n",
       "      <td>0.641828</td>\n",
       "      <td>0.632069</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.605350</td>\n",
       "      <td>0.634979</td>\n",
       "      <td>0.657202</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.652120</td>\n",
       "      <td>0.637338</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.05</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.605761</td>\n",
       "      <td>0.625926</td>\n",
       "      <td>0.660905</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.642651</td>\n",
       "      <td>0.632975</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.05</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.613169</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.637090</td>\n",
       "      <td>0.015354</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.606173</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.664609</td>\n",
       "      <td>0.643621</td>\n",
       "      <td>0.650062</td>\n",
       "      <td>0.640630</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.606584</td>\n",
       "      <td>0.642387</td>\n",
       "      <td>0.658025</td>\n",
       "      <td>0.649794</td>\n",
       "      <td>0.655414</td>\n",
       "      <td>0.642441</td>\n",
       "      <td>0.018713</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.605761</td>\n",
       "      <td>0.636214</td>\n",
       "      <td>0.660082</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.652532</td>\n",
       "      <td>0.639313</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.606996</td>\n",
       "      <td>0.639095</td>\n",
       "      <td>0.662551</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.660354</td>\n",
       "      <td>0.644910</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.636214</td>\n",
       "      <td>0.662963</td>\n",
       "      <td>0.644033</td>\n",
       "      <td>0.647592</td>\n",
       "      <td>0.639148</td>\n",
       "      <td>0.019190</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.662140</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>0.643593</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.2</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.658436</td>\n",
       "      <td>0.650206</td>\n",
       "      <td>0.662413</td>\n",
       "      <td>0.649026</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.2</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.640741</td>\n",
       "      <td>0.660905</td>\n",
       "      <td>0.676132</td>\n",
       "      <td>0.678189</td>\n",
       "      <td>0.683409</td>\n",
       "      <td>0.667875</td>\n",
       "      <td>0.015496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.2</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.629218</td>\n",
       "      <td>0.645267</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>0.655967</td>\n",
       "      <td>0.661589</td>\n",
       "      <td>0.650343</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.2</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.644033</td>\n",
       "      <td>0.660905</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.682305</td>\n",
       "      <td>0.684232</td>\n",
       "      <td>0.669851</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.642387</td>\n",
       "      <td>0.662551</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>0.666529</td>\n",
       "      <td>0.652154</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.646091</td>\n",
       "      <td>0.662963</td>\n",
       "      <td>0.680247</td>\n",
       "      <td>0.682716</td>\n",
       "      <td>0.688349</td>\n",
       "      <td>0.672073</td>\n",
       "      <td>0.015512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.645679</td>\n",
       "      <td>0.665432</td>\n",
       "      <td>0.688477</td>\n",
       "      <td>0.686831</td>\n",
       "      <td>0.685056</td>\n",
       "      <td>0.674295</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.646091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.690408</td>\n",
       "      <td>0.676682</td>\n",
       "      <td>0.017817</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.645679</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.688066</td>\n",
       "      <td>0.689584</td>\n",
       "      <td>0.676353</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.647325</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.695885</td>\n",
       "      <td>0.693416</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>0.679316</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.646502</td>\n",
       "      <td>0.665432</td>\n",
       "      <td>0.689712</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.688349</td>\n",
       "      <td>0.676188</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.651440</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0.693416</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>0.680139</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_tfidf__max_df param_tfidf__max_features param_tfidf__ngram_range  \\\n",
       "0                 0.01                     10000                   (1, 1)   \n",
       "1                 0.01                     10000                   (1, 2)   \n",
       "2                 0.01                     15000                   (1, 1)   \n",
       "3                 0.01                     15000                   (1, 2)   \n",
       "4                 0.01                     20000                   (1, 1)   \n",
       "5                 0.01                     20000                   (1, 2)   \n",
       "6                 0.05                     10000                   (1, 1)   \n",
       "7                 0.05                     10000                   (1, 2)   \n",
       "8                 0.05                     15000                   (1, 1)   \n",
       "9                 0.05                     15000                   (1, 2)   \n",
       "10                0.05                     20000                   (1, 1)   \n",
       "11                0.05                     20000                   (1, 2)   \n",
       "12                 0.1                     10000                   (1, 1)   \n",
       "13                 0.1                     10000                   (1, 2)   \n",
       "14                 0.1                     15000                   (1, 1)   \n",
       "15                 0.1                     15000                   (1, 2)   \n",
       "16                 0.1                     20000                   (1, 1)   \n",
       "17                 0.1                     20000                   (1, 2)   \n",
       "18                 0.2                     10000                   (1, 1)   \n",
       "19                 0.2                     10000                   (1, 2)   \n",
       "20                 0.2                     15000                   (1, 1)   \n",
       "21                 0.2                     15000                   (1, 2)   \n",
       "22                 0.2                     20000                   (1, 1)   \n",
       "23                 0.2                     20000                   (1, 2)   \n",
       "24                 1.0                     10000                   (1, 1)   \n",
       "25                 1.0                     10000                   (1, 2)   \n",
       "26                 1.0                     15000                   (1, 1)   \n",
       "27                 1.0                     15000                   (1, 2)   \n",
       "28                 1.0                     20000                   (1, 1)   \n",
       "29                 1.0                     20000                   (1, 2)   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.578601           0.614815           0.612346   \n",
       "1            0.576132           0.616049           0.623457   \n",
       "2            0.576543           0.614403           0.616049   \n",
       "3            0.583951           0.616049           0.628807   \n",
       "4            0.577778           0.615226           0.617284   \n",
       "5            0.589712           0.608642           0.629630   \n",
       "6            0.606173           0.630041           0.650206   \n",
       "7            0.610700           0.635802           0.655144   \n",
       "8            0.608230           0.627160           0.655967   \n",
       "9            0.605350           0.634979           0.657202   \n",
       "10           0.605761           0.625926           0.660905   \n",
       "11           0.613169           0.633333           0.659671   \n",
       "12           0.606173           0.638683           0.664609   \n",
       "13           0.606584           0.642387           0.658025   \n",
       "14           0.605761           0.636214           0.660082   \n",
       "15           0.606996           0.639095           0.662551   \n",
       "16           0.604938           0.636214           0.662963   \n",
       "17           0.611111           0.641975           0.662140   \n",
       "18           0.629630           0.644444           0.658436   \n",
       "19           0.640741           0.660905           0.676132   \n",
       "20           0.629218           0.645267           0.659671   \n",
       "21           0.644033           0.660905           0.677778   \n",
       "22           0.629630           0.642387           0.662551   \n",
       "23           0.646091           0.662963           0.680247   \n",
       "24           0.645679           0.665432           0.688477   \n",
       "25           0.646091           0.666667           0.690947   \n",
       "26           0.645679           0.669136           0.689300   \n",
       "27           0.647325           0.666667           0.695885   \n",
       "28           0.646502           0.665432           0.689712   \n",
       "29           0.651440           0.668724           0.693416   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.594239           0.617126         0.603425        0.014817   \n",
       "1            0.605350           0.606834         0.605564        0.016112   \n",
       "2            0.596296           0.615068         0.603672        0.015418   \n",
       "3            0.610288           0.620420         0.611903        0.015228   \n",
       "4            0.602058           0.618361         0.606141        0.015344   \n",
       "5            0.610700           0.624125         0.612562        0.013899   \n",
       "6            0.621399           0.643886         0.630341        0.015762   \n",
       "7            0.632922           0.648827         0.636679        0.015351   \n",
       "8            0.627160           0.641828         0.632069        0.016018   \n",
       "9            0.637037           0.652120         0.637338        0.018122   \n",
       "10           0.629630           0.642651         0.632975        0.018304   \n",
       "11           0.633745           0.645533         0.637090        0.015354   \n",
       "12           0.643621           0.650062         0.640630        0.019308   \n",
       "13           0.649794           0.655414         0.642441        0.018713   \n",
       "14           0.641975           0.652532         0.639313        0.018700   \n",
       "15           0.655556           0.660354         0.644910        0.020661   \n",
       "16           0.644033           0.647592         0.639148        0.019190   \n",
       "17           0.649383           0.653355         0.643593        0.017496   \n",
       "18           0.650206           0.662413         0.649026        0.011544   \n",
       "19           0.678189           0.683409         0.667875        0.015496   \n",
       "20           0.655967           0.661589         0.650343        0.011976   \n",
       "21           0.682305           0.684232         0.669851        0.015306   \n",
       "22           0.659671           0.666529         0.652154        0.013957   \n",
       "23           0.682716           0.688349         0.672073        0.015512   \n",
       "24           0.686831           0.685056         0.674295        0.016562   \n",
       "25           0.689300           0.690408         0.676682        0.017817   \n",
       "26           0.688066           0.689584         0.676353        0.017163   \n",
       "27           0.693416           0.693289         0.679316        0.019246   \n",
       "28           0.690947           0.688349         0.676188        0.017582   \n",
       "29           0.693827           0.693289         0.680139        0.017265   \n",
       "\n",
       "    rank_test_score  \n",
       "0                30  \n",
       "1                28  \n",
       "2                29  \n",
       "3                26  \n",
       "4                27  \n",
       "5                25  \n",
       "6                24  \n",
       "7                21  \n",
       "8                23  \n",
       "9                19  \n",
       "10               22  \n",
       "11               20  \n",
       "12               16  \n",
       "13               15  \n",
       "14               17  \n",
       "15               13  \n",
       "16               18  \n",
       "17               14  \n",
       "18               12  \n",
       "19                9  \n",
       "20               11  \n",
       "21                8  \n",
       "22               10  \n",
       "23                7  \n",
       "24                6  \n",
       "25                3  \n",
       "26                4  \n",
       "27                2  \n",
       "28                5  \n",
       "29                1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(grid.cv_results_).filter(regex='(param_.*)|(.*test_score)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb1c7d-b713-4ee4-82f8-d0d89fef60e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 用chi2跑跑看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efa497bd-eeeb-4339-8755-0469fcee73f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12149x3000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 584072 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用跑完後比較好的參數\n",
    "model_tfidf = TfidfVectorizer(max_df=1.0,\n",
    "                              ngram_range = (1,2),\n",
    "                              use_idf = False,\n",
    "                              # token_pattern=r\"(?u)\\b\\w+\\b\", \n",
    "                              max_features = 8000,\n",
    "                              stop_words=stopwords).fit(documents)\n",
    "\n",
    "\n",
    "X_tfidf = model_tfidf.transform(documents)\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "selector = SelectKBest(score_func=chi2, k=3000)\n",
    "fit = selector.fit(X_tfidf, y)\n",
    "# fit.scores_\n",
    "X_chi2=selector.fit_transform(X_tfidf, y)\n",
    "X_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cea6e51-0e98-4b0e-997e-5362f01e066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1134  645]\n",
      " [ 477 1389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1779\n",
      "           1       0.68      0.74      0.71      1866\n",
      "\n",
      "    accuracy                           0.69      3645\n",
      "   macro avg       0.69      0.69      0.69      3645\n",
      "weighted avg       0.69      0.69      0.69      3645\n",
      "\n",
      "[[1162  598]\n",
      " [ 492 1393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68      1760\n",
      "           1       0.70      0.74      0.72      1885\n",
      "\n",
      "    accuracy                           0.70      3645\n",
      "   macro avg       0.70      0.70      0.70      3645\n",
      "weighted avg       0.70      0.70      0.70      3645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "def train_model(classifier, train, train_label, test, test_label):\n",
    "    classifier.fit(train, train_label)\n",
    "    pred_label = classifier.predict(test)\n",
    "    print(confusion_matrix(test_label, pred_label))\n",
    "    print(classification_report(test_label, pred_label))\n",
    "\n",
    "X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf.toarray(), y, test_size=0.3)\n",
    "X_chi2_train, X_chi2_test, y_chi2_train, y_chi2_test = train_test_split(X_chi2.toarray(), y, test_size=0.3)\n",
    "\n",
    "# print(X_tfidf_train.shape)\n",
    "# print(X_chi2_train.shape)\n",
    "\n",
    "#tfidf + LR\n",
    "train_model(LogisticRegression(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "\n",
    "#chi2 + LR\n",
    "train_model(LogisticRegression(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36837f9e-cb8d-447b-9bad-91c45879e959",
   "metadata": {},
   "source": [
    "## 測試其他種model\n",
    "(因為電腦會跑到當機，所以其他model就不做optimization了)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a925dbe-61fb-42e7-a883-6f912a3c552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1162  617]\n",
      " [ 736 1130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1779\n",
      "           1       0.65      0.61      0.63      1866\n",
      "\n",
      "    accuracy                           0.63      3645\n",
      "   macro avg       0.63      0.63      0.63      3645\n",
      "weighted avg       0.63      0.63      0.63      3645\n",
      "\n",
      "[[1321  439]\n",
      " [ 752 1133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69      1760\n",
      "           1       0.72      0.60      0.66      1885\n",
      "\n",
      "    accuracy                           0.67      3645\n",
      "   macro avg       0.68      0.68      0.67      3645\n",
      "weighted avg       0.68      0.67      0.67      3645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tfidf + Bayes\n",
    "train_model(GaussianNB(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "\n",
    "#chi2 + Bayes\n",
    "train_model(GaussianNB(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bac2cba-9650-422e-9427-fbfa070935ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf + randomforest\n",
      "[[1169  610]\n",
      " [ 484 1382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68      1779\n",
      "           1       0.69      0.74      0.72      1866\n",
      "\n",
      "    accuracy                           0.70      3645\n",
      "   macro avg       0.70      0.70      0.70      3645\n",
      "weighted avg       0.70      0.70      0.70      3645\n",
      "\n",
      "====================================================================================================\n",
      "chi2 + randomforest\n",
      "[[1141  619]\n",
      " [ 518 1367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1760\n",
      "           1       0.69      0.73      0.71      1885\n",
      "\n",
      "    accuracy                           0.69      3645\n",
      "   macro avg       0.69      0.69      0.69      3645\n",
      "weighted avg       0.69      0.69      0.69      3645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #tfidf + bootstrap\n",
    "# print(\"tfidf + bootstrap\")\n",
    "# train_model(GradientBoostingClassifier(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "# print(\"=\"*100)\n",
    "\n",
    "# #chi2 + bootstrap\n",
    "# print(\"chi2 + bootstrap\")\n",
    "# train_model(GradientBoostingClassifier(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)\n",
    "# print(\"=\"*100)\n",
    "\n",
    "#tfidf + randomforest\n",
    "print(\"tfidf + randomforest\")\n",
    "train_model(RandomForestClassifier(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "print(\"=\"*100)\n",
    "\n",
    "#chi2 + randomforest\n",
    "print(\"chi2 + randomforest\")\n",
    "train_model(RandomForestClassifier(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f1bf",
   "metadata": {},
   "source": [
    "# 預測結果\n",
    "預測結果應包含`classification_report`並應用`from mlxtend.plotting import plot_confusion_matrix`繪製confision_matrix的視覺化結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d896c0-baf8-4d63-b03e-3976b20e09be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (1.21.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (56.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (3.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e006ce0-1fc9-4167-b74f-06b6f3d12406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf + logistic regression\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "chi2 + logistic regression\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "tfidf + randomforest\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEGCAYAAACO3ptGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR5ElEQVR4nO3deZRU5ZmA8edtkJYgIKDQIJugQgxhN4oSYEQdV6Jm3EfHqFFJXBBDJETjEtdBRcVMHJdRcTfGaBRUXKOCoAiIiWyKiiwqKCCrC/3NH1UgKEuj3Cpont85fU5X1e26bzf00/feqroVKSUkbdlKij2ApOIzBJIMgSRDIAlDIAmoWuwBVqhSvVaqWqtBscfQBtilrGaxR9AGmDljOp9+MjfWdNsmE4KqtRpQdvS1xR5DG+DhAT2LPYI2wOH7dV3rbe4aSDIEkgyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAyBJAzB93La3i157ZJ9Oan7jgA0374GQ07fnTcu//fVluvcoi5Df9ONYf26cUqPFgD02X8XRl28D8P65a7fuWybgs+/JRszeiSH7rsnvXruwf/ddAPvTXubk47uxW6tG39r2YWfLaBLm+Y8fP9dRZi0MKpmeecR8UvgbGAhcGxK6d0s11doL0z8mBb1a6y8/OmiLxj0xGTuPH2PldeVVi3h6mPbcfyfRzPj0yW0rP/1L/zAxyfx19dmFHRmwefLlvG7Pqdz2/2P0rhJM6a9PYU6detxVr/zOfmYQ7+1/OBrLmf7BmWFH7SAMgtBRNQH+gNtge7AtcBhWa2vGCbPXsjs+ctWXv5s6ZeMe3/+ast0bbU9r787jw8+WQLA2x8tWnnb/CVfFmROrW7Ei8/RofPuNG2W25LbaZfWALTv9JNvLfv2lElMGDuGnvsdVNAZCy3LXYP9gNdTSouBp4A9I2KL2xVpUrc6y75czq2n7MbQ33Rj95b1Vt522t4tebp/Dy46/EdUKYkiTrllmTH9fbauXp3TTziCQ/fdk1dHvrTG5VJKXHFhf86/9GqipHL/183yu2sITAZIKS0H5gN1V10gIk6NiDERMWb50gUZjlI8W1erwk4NanLO3eMY8OAELvmPNgDc/8p0zrl7HEffOJJ2TbelV8cdijzplmPZ0iW8M2UyA2+8lYuvuoFLBvRd43LPPPk4zXZsSZt2HQo8YeFleoyA1UNTE0ir3phSuhm4GaC0wc6r3VZZfDh/Ge/NWcTCZV/xxvT51KtZmrt+wde7FEPHz2anBh4sLJSyRjvQrEVLataqTdsOnfhk7pw1Ljfs0YeY9vYUjjiwBx/Onkm1aqU0aNiIvbr3LPDE2csyBLOA3QEiohZQB5iX4fo2SS9OmsM5B7SiRmluy2DWvKVUq1LCAe0b8vexM6m+VRW6ttqO+16ZXuxRtxhdu/fkhoGXsWjRQt6ZMpmGOzRZ43KDbrpz5ec3DLyMxk2aVsoIQLYhGA5cEhE1gB7AEyml8gzXV1D1a5Vyx2m7s32tUsrLE/u0acCYafPYp00Dttm6KsP6dePGp6cybPxsrhk2iYfO3ouqJSWce+84viovp9l2P+DRvj9lu5qlPDZ2Jk9N+LDY39IWo+5229PnvAs4ptc+LP9qOVde/79cf9UfeXb4UBYvWkivnnvQ++zfckCvw4s9asFEStltkUfEycA5VODhw9IGO6eyo6/NbBZtfM8MqJx/HSurw/fryptvjF3jUelMjxGklG4DbstyHZK+v8r9mIikCjEEkgyBJEMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgCUMgie8YgvzbnEuqJNb6JqgRMQhY01slbwUcCLTMaihJhbWud0Mev5brE3DTxh9FUrGsNQQppTtXfB4RHYGmKaVH8perZz+apEJZ7zGCiLgCOAu4Mn+5CfBgxnNJKqB17RqscCiwKzAWIKX0QUQ0znIoSYVVkUcNFgP1yR84jIg9gS+yHEpSYVVki+A04DGgRUS8DJQBR2Y6laSCWm8IUkqv57cCdiG3BTE5pfRl5pNJKpj1hiAitiV3sLAzsAR4JiJuTyktz3g2SQVSkWME9wHbAn8CbgV64PMIpEqlIscIylJKB6y4EBHPAhOyG0lSoVVki+AfEdFulctlwLiM5pFUBOt6rcE8cg8ZbgX0jojFQAClwKzCjCepENb1FOM6hRxEUvFU5BgBEfFToBmr7EqklIZkNZSkwqrIw4f3Ao2AhsAwoA0wDTAEUiVRkYOFP0op9QCeAwYBvcgdMJRUSVQkBHMjoja5rYEzgBbknmUoqZKoSAguAuoBQ4FqwP3AwAxnklRgFXmtwUurXOyT3SiSimVdzyM4ax1fc1JKqc3GHKRN49qMuOaQjXmXylid3c4o9gjaAJ9PnbHW29a1RbC25xEk4OzvM5CkTcu6nlB0cSEHkVQ8vsGJJEMgqWJnMf5pRLwcEVPylxtHxDnZjyapUCqyRXAjcAi5k5iSUpoBHJflUJIKqyIhqAYs4OuzGNcAtslyKEmFVZEQ3JH/qB0RpwDPkztlmaRKoiLPLLwqIvYGPgRaA79PKT2d+WSSCqZC5yNIKT1H7tWHkiqhipyPYMUpy1ZIwAcppfZZDSWpsCqya7DaU40j4ihyJyqRVEl8lycU/RX41cYeRFLxVGTXYBBf7xpsBXQEZmc5lKTCqsjBwvGrfF4O3A68kck0koqiIiHonFI6M/NJJBVNRY4RNIyInTOfRFLRVGSL4BNgbEQ8B6x8B+SU0uGZTSWpoCoSgnvzH5IqqYqEoG1KafCqV0TEecA/shlJUqGt9RhBRFTLv5/BKRFRMyJq5T92BXoXbkRJWVvXFsHR5N7QpDW5hwsjf/0M4NKM55JUQOs6eekQYEhEXJtS6lvAmSQV2HofPjQCUuXnyUslGQJJhkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShkAShmCjWbBgAc12aMBdd97B4sWLOazXQbTaqTmHHnIgixcvXrlcSoleB+3PL086sXjDbsHOOaEn04ZfxhnH9gDgjGN78PLd/Zg09GIu6H3QyuVOP6obEx+/iPEPn89eHVoCsHvbHXnmtj6M++v5XPe7I4sxfmYyDUFE9IuI2RHRJ8v1bAou++PFlJU1BODeu++irKwhk6a+y4/btuP+e+9ZudzQxx/jow8/LNaYW7zhIyfy5Mv/Wnl57FvT6XbC1bQ77I+ceGgXmpTVoUb1agw47QB+ctSVHNn3Fi45sxcAHXdtylHn3kKnIy6j4w+b0nOP1sX6Nja6rLcIngSGZryOops0cSKvvTqagw7J/YepWasWTZs1IyLo0LET1apVA2DZsmVcevGF9O13XjHH3aL96+1ZzPxo/srLI8dPIyJo16ox8xcuZdacBXz5VTkzP5rPoiWfM/X9j/n0syUA/Pn+f/DJ/MWUlydGT3iXJg3rFOm72PgyDUFK6U1yb6NeaaWUOK9fX64ZdAMlJbkf52GH/5xRr4xk4H9fybNPD+dnhx0OwA3XXctxx/8XDRs2LObI+oZHBvfmudv7cvYVD7B8eTlffPkVtz70Mg8OOpV+J+3HLX956Vtf07lNM8ZP/KAI02ajqMcIIuLUiBgTEWPmzJ1TzFG+s8f+/igtWu5Ex06dVl436pWRtGi5E2UNynh19CimTpnCjBkzeGLYUHr/+owiTqs1OeRXf6LDzy/luv5HUr9uTX6wdTV67tGaW/7yEl077sRubZqvtvyB3dqwZNkXjJ9Uef7GVS3mylNKNwM3A3Tq1DkVc5bv6qG/PMCUSZPottcezJw5g9LSUt6dNo133p9Jo0aNaNqsGYOuHUiXLnsxf/489u7elYULP2PunDlcPfAqfuNuwiZh6vsf8/zoyfTs0pry5YlxEz9g+Ii3eOaViYx96PcMvuc5Plu0jHatGnPp2T/joNNvLPbIG5WPGnxPQ+6+j1FjxvHiiFH84qRT+N2AC+je4994+aUXAZg6ZQrLli7l12eexbgJb/HiiFFcP/h/2P+Ag4xAkdWtXYNzT9yHKlVKqFlja3p2ac302Z9SpWoJP2m7I1tVrULd2jWoX68W1baqSvMd6nHvwJM5+fwhzJ6zoNjjb1RF3SKorAZdfyOnnvILLvrD76lfvwE333p7sUcS0HD72vxtcG8a1KtFeXk5B/doy4hx7/Dy3f2oW7sGQx4dxYix7zDqjXfp0q4FEx65gPLyxO8G/Y258xbxyODe1PhBKYPPP4aqVUqYNO1DThxwR7G/rY0iUspmizwiGgHDgDJgOTAppdRzbct36tQ5jRg9JpNZlI06u3m8Y3Py+eQHKV/ycazptsy2CFJKs4D2Wd2/pI3HYwSSDIEkQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJQyAJiJRSsWcAICLmAO8Xe44MbAfMLfYQ2iCV9d+sWUpp+zXdsMmEoLKKiDEppc7FnkMVtyX+m7lrIMkQSDIEhXBzsQfQBtvi/s08RiDJLQJJhkAShiBTEfHLiPhnRLwSETsWex6tX0T0i4jZEdGn2LMUUtViD1BZRUR9oD/QFugOXAscVtShVBFPAq2KPUShuUWQnf2A11NKi4GngD0jwp/3Ji6l9CYwo9hzFJr/MbPTEJgMkFJaDswH6hZzIGltDEG2Vv351gR8rFabJEOQnVnk9zUjohZQB5hX1ImktTAE2RkOdIiIGkAP4ImUUnlxR5LWzEcNMpJSmhMRlwOjgYXAsUUeSesREY2AYUAZsDwiDkkp9SzyWAXhU4wluWsgyRBIwhBIwhBIwhBIwhBssSKifUS8kP/8hIg4YR3LNouI/Tfw/sdHRPNvXPdeRGy7jq85MSKu24B1vBAR7TdkLq2ZzyMQKaUh61mkDbAvuVfmqRJyi2AzEhHNI2JURNyTP8/BfRFRmr/tjYi4LH/ug8j/lZ8UERMj4oj8MjtExPMRMQ64YJX7vWjF6+/z6xgeERMi4oGIaAX8GTgu/1e+NCJaRsSL+fu/MyKq5td5ef66x4F66/leLsx/L1Mj4qhVbmoVEU9ExJSI6L/K8v3z9/1mRHTfWD9T5RiCzU8L4A/Aj4GtgWPy17cBpqSUugC7AMcD7YCOwG8joiq5cyI8kFLqANy1lvu/E7gppdQWODelNDm/vntSSu1TSp+TO7nnr4EfAtOBQ4H9ga75dR4HrO/p1EOBLuRern3lKtdXB47Iz/2riGgRET2BH+W/x+7A5eu5b20gdw02P7NSSu8ARMRTQCfgDmAJsGITfx9gV3JPbwbYlty79/QgFwiA9755xxGxDbBjSulhgJTSt16XHxE1yf0CrwhJKbl3BWoK3JEPxecRsb4XWL0L9CH3C7/DKtePTyktyq9rZP723clFZkx+mZrruW9tIEOweVsOLF3xefr6+eIlwJ0ppQGrLpzfjagBfLGW+6tSgXUGuXMrdFhlfUTEDVTwFzT/aszngIuAW4BD1rLocnKBKwGuSCltcacZLxR3DTY/dSJi24ioBvwnuV+ob3oWODoiGgBERNP89a8BB+c/3+2bX5RSWgB8FBEH579u54gIYCb5v9oppc/IbU0clV+mLD/LaODgiCiJiMbkTszyrVWQ++OzC/AV8AjQnNzuwApNI6JKRDQktxXwKrkzPJ0aEdvkj0U0+cb96XsyBJufEnK7ABOAkeR+SVaTUnoLuBB4ISLGAmfnb+oD9I2I18j9Aq7J8UD/iJhAbt99a+AVYOeIGBsRZfllTssvcy9QH3iQ3DkY/glcDbyzhvseDpyZn30aMB44mdxuwgrl5EL2PNA3pTQ3pTQ8f/+v5z+OzC/7DLljFfqefPXhZiT/uPwjKaX2RR5FlYxbBJLcIpDkFoEkDIEkDIEkDIEkDIEk4P8B3a16npA20HQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "chi2 + randomforest\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "tfidf + Bayes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "chi2 + Bayes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cm_model(classifier, train, train_label, test, test_label):\n",
    "    classifier.fit(train, train_label)\n",
    "    pred_label = classifier.predict(test)\n",
    "    return confusion_matrix(test_label, pred_label)\n",
    "\n",
    "print(\"tfidf + logistic regression\")\n",
    "cm_1 = cm_model(LogisticRegression(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_1)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"chi2 + logistic regression\")\n",
    "cm_2 = cm_model(LogisticRegression(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_2)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"tfidf + randomforest\")\n",
    "cm_3 = cm_model(RandomForestClassifier(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_3)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"chi2 + randomforest\")\n",
    "cm_4 = cm_model(RandomForestClassifier(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_4)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"tfidf + Bayes\")\n",
    "cm_5 = cm_model(GaussianNB(), X_tfidf_train, y_tfidf_train, X_tfidf_test, y_tfidf_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_5)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"chi2 + Bayes\")\n",
    "cm_6 = cm_model(GaussianNB(), X_chi2_train, y_chi2_train, X_chi2_test, y_chi2_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_6)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40528918",
   "metadata": {},
   "source": [
    "# 分析預測結果\n",
    "Q1. 你把什麼樣的特徵丟進去當自變項（最基本要有貼文，但你還可以丟貼文的發文者、時間、標題、前十則回文內容、回文作者）？\n",
    "> 我丟了「貼文內容與標題」作自變項，只是我為了將標題內的字詞與內文的字詞分開做考慮，所以將內文的斷詞結果存在documents1，標題的斷詞結果每個詞加上前綴\"t\"存入socuments2，再將兩者合併成一個documents後丟進tfidf做featuring。\n",
    "\n",
    "Q2. 你認為這個模型的分類能力好嗎？請說明模型訓練結果。\n",
    "> 我覺得訓練效果還可以吧，看最後confusion matrix的結果也沒有甚麼imbalance的現象，只是好像因為記憶體容量不夠所以不能將tfidf的 max features數量射程最optimize的20000筆，只能在tfidf抓最大的8000的變數，chi2抓最大的3000個變數去試試各個模型。\n",
    "\n",
    "> 以經過optimize的LR model來說有0.7的precision rate跟recall rate，且轉換成使用chi2(k=3000)時訓練結果也沒有甚麼變化，只有0的recall rate跟1的precision rate增加2%。然而因為電腦配置的關係我沒有再針對其他其他model做optimize，這時就能看到\"使用LR optimize後的X自變項參數\"運用在其他model上效果有點參差不齊。在bayes model不論是precision rate或是recall rate平均都掉了3~5%的準確率，但在random forest下跑出來的acurracy差不多。\n",
    "\n",
    "Q3. 你認為ptt貼文內容適合拿來做訓練資料嗎？為什麼？\n",
    "> 我覺得應該不太好，斷詞後的內容實在是太多了(在加入max features前有22萬筆features)。相對地代表每一篇文章的vector就沒甚麼代表性。\n",
    "\n",
    "Q4. 若加入其他參考特徵後，模型有什麼樣的改變呢（如果你沒做的話就不用回答）？\n",
    "> 雖然我沒有做加入標題內容的前後對比看模型跑出來的結果，但我覺得加入標題變項後對於訓練出來的結果應有不小提升。因為大家都是先看標題在選擇說要不要點進這篇貼文去看內容的，或是有些人是直接看了標題(因為該篇標題可能是已經在網路上火紅好一陣子的話題)就直接轉去看留言跟人互戰起來了@@所以如果可以的話應該將留言內容也加入進模型訓練的參數會好上一些。\n",
    "\n",
    "Q5. 如果你在Daily Scrum上要回報這個任務，請用100字以上、200字以內精簡且精準地回報模型訓練結果。\n",
    "> 我們對這些ptt的回文資料做了簡單的模型訓練，使用的模型有logistic regression, Bayes prediction, random forest decion tree三種，其中表現最好的是LR與random forest兩種模型，對於這篇貼文會「爆」的預測準確率分別達到70%及69%，並且實際結果為「爆」的貼文我們的模型有成功抓取到其中的73~74%。然而以上的結果僅只有對LR model做參數的optimize，另外兩項model沒有做optimize，且我們訓練的自變項只考慮了貼文內容與標題兩種變項。\n",
    "\n",
    "> 考慮到目前的訓練結果，接下來如果要做進一步分析的話我們會將貼文底下留言的內容也考慮進自變項，並對random forest model做最佳化的參數調整。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
